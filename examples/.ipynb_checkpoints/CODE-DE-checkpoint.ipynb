{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FORCE on CODE-DE using a Jupyter Notebook\n",
    "\n",
    "This is an introduction on how to use FORCE and its submodules on the CODE-DE platform using a Jupyter Notebook.\n",
    "\n",
    "It is based on this [this knowledge-based article](https://herelinktoarticle.com) on CODE-DE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: this notebook requires the bash kernel.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook also assumes, that you have cloned the ``CODE-DE-Cloud/community_FORCE`` repository before, using:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# clone repository\n",
    "cd /home/eouser\n",
    "git clone https://github.com/CODE-DE-Cloud/community_FORCE.git\n",
    "cd community_FORCE\n",
    "mkdir test\n",
    "cd examples\n",
    "\n",
    "# start Jupyter Notebook (in this case with port forwarding)\n",
    "jupyter notebook \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /home/eouser/community_FORCE/examples/parameter_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a Jupyter Notebook, CODE-DE users can make use of the full functionality of FORCE, including all submodules.\n",
    "\n",
    "But first, let's set an alias for more convenient Docker use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "alias dforce=' \\\n",
    "  docker run \\\n",
    "  -v $HOME:$HOME \\\n",
    "  -v /codede:/codede \\\n",
    "  -v /codede/community/FORCE/C1/L2/ard:/force \\\n",
    "  -w $PWD \\\n",
    "  -u $(id -u):$(id -g) \\\n",
    "  -t \\\n",
    "  --rm \\\n",
    "  davidfrantz/force'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following statements in order to obtain information about your current FORCE version as well as usage recommendations and all currently available FORCE modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FORCE version: 3.7.5\n",
      "\n",
      "##########################################################################\n",
      "\n",
      "Hello user! You are currently running FORCE v. 3.7.5\n",
      "Framework for Operational Radiometric Correction for Environmental monitoring\n",
      "Copyright (C) 2013-2021 David Frantz, david.frantz@geo.hu-berlin.de\n",
      "+ many community contributions.\n",
      "\n",
      "FORCE is free software under the terms of the GNU General Public License as published by the Free Software Foundation, see <http://www.gnu.org/licenses/>.\n",
      "\n",
      "Thank you for using FORCE! This software is being developed in the hope that it will be helpful for you and your work.\n",
      "\n",
      "However, it is requested that you to use the software in accordance with academic standards and fair usage. Without this, software like FORCE will not survive. This includes citation of the software and the scientific publications, proper acknowledgement in any public presentation, or an offer of co-authorship of scientific articles in case substantial help in setting up, modifying or running the software is provided by the author(s).\n",
      "\n",
      "At minimum, the citation of following paper is requested:\n",
      "Frantz, D. (2019). FORCE—Landsat + Sentinel-2 Analysis Ready Data and Beyond. Remote Sensing, 11, 1124\n",
      "\n",
      "Each FORCE module will generate a \"CITEME\" file with suggestions for references to be cited. This list is based on the specific parameterization you are using.\n",
      "\n",
      "The documentation and tutorials are available at force-eo.readthedocs.io\n",
      "\n",
      "FORCE consists of several components:\n",
      "\n",
      "Level 1 Archiving System (L1AS)\n",
      "+ force-level1-csd       Download from cloud storage + maintenance of Level 1 Landsat and Sentinel-2 data pool\n",
      "+ force-level1-landsat   Maintenance of Level 1 Landsat data pool (deprecated)\n",
      "+ force-level1-sentinel2 Download from ESA + maintenance of Level 1 Sentinel-2 data pool (deprecated)\n",
      "\n",
      "Level 2 Processing System (L2PS)\n",
      "+ force-level2           Level 2 processing of image archive\n",
      "+ force-l2ps             Level 2 processing of single image\n",
      "\n",
      "Water Vapor Database (WVDB)\n",
      "+ force-lut-modis        Generation and maintenance of water vapor database using MODIS products\n",
      "\n",
      "Higher Level Processing System (HLPS)\n",
      "+ force-higher-level     Higher level processing (compositing, time series analysis, ...)\n",
      "\n",
      "Auxiliary (AUX)\n",
      "+ force-parameter        Generation of parameter files\n",
      "+ force-magic-parameters Replace variables in parameter file with vectors\n",
      "+ force-train            Training (and validation) of Machine Learning models\n",
      "+ force-synthmix         Synthetic Mixing of training data\n",
      "+ force-qai-inflate      Inflate QAI bit layers\n",
      "+ force-tile-extent      Compute suggested processing extent and tile allow-list based on a vector layer\n",
      "+ force-tile-finder      Find the tile, pixel, and chunk of a given coordinate\n",
      "+ force-tabulate-grid    Extract the processing grid as shapefile\n",
      "+ force-cube             Ingestion of auxiliary data into datacube format\n",
      "+ force-procmask         Processing masks from raster images\n",
      "+ force-pyramid          Generation of image pyramids\n",
      "+ force-mosaic           Mosaicking of image chips\n",
      "+ force-stack            Stack images, works with 4D data model\n",
      "+ force-mdcp             Copy FORCE metadata from one file to another\n",
      "\n",
      "##########################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dforce force -v\n",
    "dforce force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All higher-level functionalities are subsumed under the higher-level component: Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-optional arguments are missing.\n",
      "Usage: force-higher-level [-h] [-v] [-i] parameter-file\n",
      "\n",
      "  -h  = show this help\n",
      "  -v  = show version\n",
      "  -i  = show program's purpose\n",
      "\n",
      "  Positional arguments:\n",
      "  - 'parameter-file': parameter file for any higher level submodule\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "dforce force-higher-level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to see the requirements to execute this component.\n",
    "\n",
    "Each FORCE component can be run with the *-h* parameter to show help, with the *-v* parameter to show the component’s version, and with the *-i* parameter to show the program’s purpose. For data processing, *force-higher-level* requires a parameter-file that will determine which submodule to execute, for example time series analysis or machine learning predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submodules\n",
    "\n",
    "FORCE higher-level consists of ten submodules, all executable with\n",
    "\n",
    "``dforce force-higher-level parameter-file``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 3 Compositing\n",
    "\n",
    "The Level 3 Compositing submodule generates temporal aggregations of Analysis Ready Data (ARD) to provide seamless, gap free, and highly Analysis Ready Data (hARD) over very large areas. hARD are excellent inputs for many machine learning algorithms, e.g. for land cover / change classification purposes. The aggregation is performed using a parametric weighting scheme-based selection algorithm commonly known as best available pixel (BAP) compositing, using static target dates [(Griffiths et al. 2013)](https://ieeexplore.ieee.org/document/6415303), or dynamic target dates [(Frantz et al. 2017)](https://www.sciencedirect.com/science/article/abs/pii/S0034425717300032?via%3Dihub). That means that this submodule generates spatially consistent large-area data with high-quality pixel values for a specified date, or a specified phenological status.\n",
    "\n",
    "### Input Data\n",
    "\n",
    "This submodule requires ARD as available in the FORCE DataCube as input for static target dates. Computing dynamic target dates based on surface phenology requires feature input from a Land Surface Phenology (LSP) dataset, which can be generated using the *Time Series Analysis* submodule.\n",
    "\n",
    "### Parameter file\n",
    "\n",
    "An empty Level 3 Compositing parameter file can be gernerated with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``dforce force-parameter force-prm-LEVEL3.prm LEVEL3``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: we are skipping this step as the community repository already contains working examples.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the Level 3 Compositing submodule creates temporally aggregated data, PROCESSING TIMEFRAME parameters describe the date range, i.e. the overarching study period, and day-of-year range, i.e. possible seasonal restrictions, of all considered clear-sky observations. Depending on whether a Best Available Pixel Composite (BAP) or Phenology Adaptive Compositing (PAC) should be performed, the respective parameters are of importance. If you require PAC, set LSP_DO to TRUE. Otherwise, the following parameters will be ignored. For an encompassing description of parameterization, please see the [FORCE documentation](https://force-eo.readthedocs.io/en/latest/components/higher-level/l3/param.html).\n",
    "\n",
    "### Output Data\n",
    "\n",
    "Output data are organized in the FORCE DataCube format.\n",
    "\n",
    "Example filename: *20160701_LEVEL3_LNDLG_BAP.tif*\n",
    "\n",
    "Each file name indicates the target date (here: 20160701), the sensor ID of the selected sensor family (e.g. Landsat legacy bands: *LNDLG*), and the product type (e.g. Best Available Pixel *BAP*).\n",
    "\n",
    "In the parameter file, the user can select four types of output data. *OUTPUT_BAP* is the best pixel composites, i.e. a reflectance product for static target dates. The scale is 10000, and nodata value is -9999. The product contains multiple bands, which represent wavelengths. The number of bands is dependent on the sensor used. *OUTPUT_INF* contains information about the selected observation in the BAP product, for example Quality Assurance Information of the best observation, or the acquisition dates of the BAP composite. *OUTPUT_SCR* contains the scores of the selected observation in the BAP product, i.e. information about the adequacy of the selected pixel for the expected target date. *OUTPUT_OVV* is a small quicklook image of the composite without geographic reference.\n",
    "\n",
    "### Working Example\n",
    "    \n",
    "CODE-DE users can download a working example of a Level 3 Compositing parameter file [here](https://github.com/CODE-DE-Cloud/community_FORCE/tree/main/examples/parameter_files), or directly use the parameter file as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dforce force-higher-level force-prm-LEVEL3.prm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This generates a best-pixel composite for the target year 2020 (target day of year 180) from all Sentinel-2 A and B clear sky observations from 2019 to 2021 for Berlin.\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "Please refer to the [FORCE Level 3 Compositing documentation](https://force-eo.readthedocs.io/en/latest/components/higher-level/l3/index.html#level3) with a processing workflow illustration for further detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear Sky Observations\n",
    "\n",
    "The Clear Sky Observations submodule assists in data availability mining. It assesses availability metrics of all clear-sky observations of a specified set of sensors within a specified period. That encompasses, for example, the number of observations, or the average number of days between observations.\n",
    "\n",
    "### Input Data\n",
    "\n",
    "This submodule requires ARD as available in the FORCE DataCube as input, as it assesses data availability of ARD.\n",
    "\n",
    "### Parameter file\n",
    "\n",
    "Create a Clear Sky Observations parameter file with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``dforce force-parameter force-prm-CSO.prm CSO``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: we are skipping this step as the community repository already contains working examples.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key parameters for the Clear Sky Observation submodule are the bin width that is used to summarize CSOs (e.g. 1 for monthly, 12 for annual), as well as the metrics to be calculated on CSOs. Multiple metrics can be computed at the same time. For an encompassing description of parameterization, please see the [FORCE documentation](https://force-eo.readthedocs.io/en/latest/components/higher-level/cso/param.html).\n",
    "\n",
    "### Output Data\n",
    "\n",
    "Output data are organized in the FORCE DataCube format.\n",
    "\n",
    "Example filename: *2000-2010_001-365-03_HL_CSO_LNDLG_NUM.tif*\n",
    "\n",
    "The output represents the clear sky observation statistics selected by the user in the parameter file. Each file name indicates the selected period (year and day-of-year: *2000-2010_001-365*), the selected sensor ID (e.g. Landsat legacy bands: *LNDLG*), and the respective statistics (Number of Observations: *NUM*). Please see the [FORCE documentation](https://force-eo.readthedocs.io/en/latest/components/higher-level/cso/format.html) for the complete naming convention.\n",
    "\n",
    "### Working Example\n",
    "\n",
    "CODE-DE users can download a working example of a Clear Sky Observations parameter file [here](https://github.com/CODE-DE-Cloud/community_FORCE/tree/main/examples/parameter_files), or directly use the parameter file as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dforce force-higher-level force-prm-CSO.prm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: we are skipping this step as the community repository already contains working examples.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This generates a monthly overview of all clear sky observations of all available Sentinel-2 A and B images for 2020 for Berlin.\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "Please refer to the [FORCE Clear Sky Observations documentation ](https://force-eo.readthedocs.io/en/latest/components/higher-level/cso/index.html#cso) with a processing workflow illustration for further detail.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Analysis\n",
    "    \n",
    "The Time Series Analysis submodule provides out-of-the-box time series preparation and analysis functionality. The Time Series Analysis submodule provides a very large variety of different data output types, including hARD and hARD+ datasets that can be used as an input to the Machine Learning submodule or directly analysed. The submodule can, for example, generate Land Surface Phenology metrics, time series interpolation, change and trend analyses, or spectral-temporal metrics.\n",
    "\n",
    "### Input Data\n",
    "\n",
    "This submodule requires ARD as available in the FORCE DataCube as input, as it generates time series metrics from ARD.\n",
    "\n",
    "### Parameter file\n",
    "\n",
    "Create a Time Series Analysis parameter file with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``dforce force-parameter force-prm-TSA.prm TSA``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: we are skipping this step as the community repository already contains working examples.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Time Series Analysis submodule parameter file is one of the more complex parameter files (but also one of the most powerful ones). Here, the user can select numerous indices and metrics to be computed. While this is very handy, please keep in mind that depending on parameterization you can potentially generate an absurd number of results and quickly fill up disc space. Fully parameterized, this submodule can output 5508 products! Each of these products are multi-band images. Some of these products, e.g. interpolated time series, can have 1000s of bands. Try to reduce the number of metrics (e.g. in *INDEX = …*) or outputs (e.g. by setting *OUTPUT_XXX = FALSE* if not required). While some parameters are rather self-explanatory, e.g.\n",
    "\n",
    "```\n",
    "######## SPECTRAL TEMPORAL METRICS\n",
    "######## -------------------------------------------------------------\n",
    "OUTPUT_STM = TRUE\n",
    "STM = Q25 Q50 Q75 AVG STD\n",
    "```\n",
    "\n",
    "Some might require explanation. For example, *FOLDING PARAMETERS* describe the temporal organization of the time series analysis.\n",
    "\n",
    "```\n",
    "FOLD_TYPE = AVG\n",
    "STANDARDIZE_FOLD = NONE\n",
    "OUTPUT_FBY = TRUE\n",
    "OUTPUT_FBQ = FALSE\n",
    "OUTPUT_FBM = TRUE\n",
    "OUTPUT_FBW = FALSE\n",
    "OUTPUT_FBD = FALSE\n",
    "OUTPUT_TRY = FALSE\n",
    "OUTPUT_TRQ = FALSE\n",
    "OUTPUT_TRM = FALSE\n",
    "OUTPUT_TRW = FALSE\n",
    "OUTPUT_TRD = FALSE\n",
    "OUTPUT_CAY = FALSE\n",
    "OUTPUT_CAQ = FALSE\n",
    "OUTPUT_CAM = FALSE\n",
    "OUTPUT_CAW = FALSE\n",
    "OUTPUT_CAD = FALSE\n",
    "```\n",
    "    \n",
    "This outputs yearly and monthly time series of the average of all indices requested in *SPECTRAL INDEX* as well as a trend analysis over yearly and weekly average values. For an encompassing description of parameterization, please see the [FORCE documentation ](https://force-eo.readthedocs.io/en/latest/components/higher-level/tsa/param.html) FORCE documentation. It is important to understand the effect of each parameter in order to limit processing time to the necessary amount.\n",
    "\n",
    "### Output Data\n",
    "\n",
    "Output data are organized in the FORCE DataCube format.\n",
    "\n",
    "Example filename: *1984-2020_182-274_HL_TSA_LNDLG_TCG_STM.tif*\n",
    "\n",
    "As the Time Series Analysis submodule provides a huge variety of possible outputs, output naming conventions are similarly complex. In this example, Tasseled Cap Greenness (TCG) metrics for all clear-sky observations between 1984 and 2020, and between day of year 182 and 274, have been computed for Landsat Legacy Bands (LNDLG). After the temporal and sensor information, the file name contains information about a possibly used index (or band), and product type (e.g. STM for spectral-temporal metrics. Product type can represent time series metrics, phenological metrics, or polarmetrics. In the latter cases, additional tags are used to describe the output as well as possible. Output file names are highly dependent on the choices the user made in the corresponding parameter file. Please see the [FORCE documentation](https://force-eo.readthedocs.io/en/latest/components/higher-level/tsa/format.html) for the complete naming convention.\n",
    "\n",
    "### Working Example\n",
    "\n",
    "CODE-DE users can download a working example of a Time Series Analysis  parameter file [here](https://github.com/CODE-DE-Cloud/community_FORCE/tree/main/examples/parameter_files), or directly use the parameter file as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dforce force-higher-level force-prm-TSA.prm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This generates the median, maximum, mean, 25th and 75th percentile of the Normalized Difference Vegetation Index (NDVI), Tasseled Cap Greenness, and reflectance, from all Sentinel-2 A and B clear sky observations for 2020 for Berlin.\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "Please refer to the [FORCE Time Series Analysis documentation](https://force-eo.readthedocs.io/en/latest/components/higher-level/tsa/index.html#tsa) with a processing workflow illustration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling\n",
    "\n",
    "The Sampling submodule provides a point-based extraction routine of features for training and validation purposes.\n",
    "\n",
    "### Input Data\n",
    "\n",
    "The Sampling submodule requires a point-based dataset as well as cubed feature datasets where samples should be extracted. The point-based dataset is provided by a list of point coordinates and class labels (with one line per point).\n",
    "\n",
    "### Parameter file\n",
    "\n",
    "Create a Sampling parameter file with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``dforce force-parameter force-prm-SMP.prm SMP``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: we are skipping this step as the community repository already contains working examples.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sampling parameter file uses *INPUT_FEATURE* to point at the specific features from which samples should be extracted at given locations. These locations are provided by a list of point coordinates and class labels (*FILE_POINTS*). *FILE_SAMPLE*, *FILE_RESPONSE* and *FILE_COORDINATES* are the paths where the samples, the response (i.e. class labels), and the respective coordinates are stored.\n",
    "\n",
    "### Output Data\n",
    "\n",
    "The output of the Sampling submodule are three comma-separated text files: Samples, Response, and Coordinates, in the previously specified location.\n",
    "\n",
    "### Working Example\n",
    "\n",
    "CODE-DE users can download a working example of a Sampling  parameter file [here](https://github.com/CODE-DE-Cloud/community_FORCE/tree/main/examples/parameter_files), or directly use the parameter file as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dforce force-higher-level force-prm-SMP.prm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This generates samples of reflectance and Tasseled Cap Greenness metrics (25ht, 50th, 75th percentile and average/maximum) of all clear sky observations of Sentinel-2 A/B imagery as generated by the parameter file presented in the Time Series Analysis section. Samples are linked to a land cover class label.\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "Please refer to the [FORCE Sampling documentation](https://force-eo.readthedocs.io/en/latest/components/higher-level/smp/index.html#smp) for further detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "The Machine Learning submodule generates maps from machine learning predictions. This submodule can generate quantitative or qualitative predictions, i.e. through regression or classification. The resulting maps can be directly used to fuel research questions without any further processing.\n",
    "\n",
    "### Input Data\n",
    "\n",
    "Typically, this submodule is fed with hARD products (features), i.e. seamless and gap free aggregate products. hARD products can e.g. be generated by the Time Series Analysis, Level 3 Compositing, Texture Metrics, and Landscape Metrics submodules - or external hARD can be ingested using [force-cube](https://force-eo.readthedocs.io/en/latest/components/auxilliary/cube.html). Machine learning models are trained using [force-train](https://force-eo.readthedocs.io/en/latest/components/auxilliary/train.html).\n",
    "\n",
    "### Parameter file\n",
    "\n",
    "Create a Machine Learning parameter file with\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``dforce force-parameter force-prm-ML.prm ML``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: we are skipping this step as the community repository already contains working examples.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features of hARD as an input to the Machine Learning parameter file. For example,\n",
    "\n",
    "*INPUT_FEATURE = 2018-2018_001-365_LEVEL4_TSA_SEN2L_NDV_STM.tif 1 2 3 4 5 6*\n",
    "\n",
    "indicates the use of the first six bands of a time series analysis file that computed temporal statistics for the year 2018 on NDVI values.\n",
    "\n",
    "While\n",
    "\n",
    "*DIR_MODEL = NULL*\n",
    "\n",
    "indicates the directory where the models to be used are stored,\n",
    "\n",
    "*FILE_MODEL = biomass-1.xml biomass-2.xml biomass-3.xml*\n",
    "\n",
    "specifies the model set used for prediction. The basename of the machine learning model(s) (.xml) must be given. One or multiple models can be given. The predictions of the models are aggregated into the final prediction. The aggregation function is the average for regression problems, and the mode for classification problems. This parameter can be given multiple times, in which case multiple regressions/classifications can be computed. Then output files will have as many bands as modelsets are given. Important: The models must have been trained with the exact same number of features as given in *INPUT_FEATURE*.\n",
    "\n",
    "*ML_METHOD*\n",
    "\n",
    "is the Machine learning method.\n",
    "\n",
    "*ML_CONVERGENCE*\n",
    "\n",
    "applies if multiple models are given for a modelset, and machine learning method is of regression flavor. The models are blended into the final prediction. Processing time scales linearly with the number of models. However, the blended prediction will likely converge with increasing numbers of models, thus it may not be necessary to compute all models. This parameter sets the convergence threshold. If the predictions differ less than this value (when adding another model), no more model will be added, which speeds up processing. For an encompassing description of parameterization, please see the [FORCE documentation](https://force-eo.readthedocs.io/en/latest/components/higher-level/ml/param.html).\n",
    "\n",
    "### Output Data\n",
    "\n",
    "Output data are organized in the FORCE DataCube format.\n",
    "\n",
    "Example filename: *XXX_HL_ML_MLP.tif*\n",
    "\n",
    "The output of the Machine Learning submodule is highly individual, depending on what response variable was chosen by the user. This is why users can also choose a naming base (here represented by *XXX*), followed by an indicator for higher level products (*HL*), the machine learning submodule tag (*ML*), and a specific output type (here: *MLP*). In the parameter file, the user can select which data products to generate. *MLP* is the machine learning prediction.* MLI* describes the number of models used when *ML_CONVERGENCE* is used. *MLU* describes the standard deviation of all predictions that are blended into the final prediction. This only makes sense when multiple models are given in a model set. When Random Forest Classification is used (i.e. *ML_METHOD = RFC*), RFP describes the pixel-wise class probabilities, and *RFM* describes the Random Forest margin.\n",
    "\n",
    "### Working Example\n",
    "\n",
    "This example uses the samples created in the Sampling section of this article. In a first step, a random forest classifier is trained. CODE-DE users can download the training  parameter file [here](https://github.com/CODE-DE-Cloud/community_FORCE/tree/main/examples/parameter_files), or directly use the parameter file as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dforce force-train force-prm-TRAIN.prm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a next step, the output model is used in a Machine Learning  parameter file to predict land cover classes across the state of Berlin. CODE-DE users can download the  parameter file [here](https://github.com/CODE-DE-Cloud/community_FORCE/tree/main/examples/parameter_files), or directly use the parameter file as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dforce force-higher-level force-prm-ML.prm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file supposes that the CODE-DE user has performed the Time Series Analysis example parameter file to create spectra-temporal metrics of the study area. Then, a sampling as described in the Sampling section is required. Final maps predict land cover (built-up surfaces, vegetation, soil, water) in the Berlin area (Figure 3).\n",
    "\n",
    "![](https://github.com/CODE-DE-Cloud/community_FORCE/blob/main/examples/aux_data/img.PNG?raw=true)\n",
    "*Figure 3 Land cover as predicted using the above sampling → training → machine learning prediction workflow with a Random Forest Classifier. Red: Built-Up Surfaces, Green: Vegetation, Yellow: Soil, Blue. Water.*\n",
    "Figure 3 Land cover as predicted using the above sampling → training → machine learning prediction workflow with a Random Forest Classifier. Red: Built-Up Surfaces, Green: Vegetation, Yellow: Soil, Blue. Water.\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "Please refer to the [FORCE Machine Learning documentation ](https://force-eo.readthedocs.io/en/latest/components/higher-level/ml/index.html#ml) with a processing workflow illustration and the example application in section 5 for further detail.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Texture Metrics\n",
    "\n",
    "The Texture Metrics submodule generates spatially aggregated data (hARD) using morphological image analysis. Texture metrics are computed considering not only a single pixel value, but also values of all surrounding pixels within a specified radius, using a variety of morphological operators. This way, spatially contextual information can be made use of, for example three-dimensional shadow information.\n",
    "\n",
    "### Input Data\n",
    "\n",
    "This submodule typically uses hARD products, i.e. seamless and gap free aggregate products. However, texture metrics can similarly be computed on ARD as available in the FORCE DataCube, if single scenes are of interest. Texture metrics can, of course, also be calculated on external (cubed) datasets if the user’s workflow requires this.\n",
    "\n",
    "### Parameter file\n",
    "\n",
    "Create a Texture Metrics parameter file with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``dforce force-parameter force-prm-TXT.prm TXT``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: we are skipping this step as the community repository already contains working examples.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Texture Metrics parameter file uses an *INPUT_FEATURE* parameter that points at all features that Texture Metrics should be computed for (file name followed by an enumeration of bands).\n",
    "\n",
    "```\n",
    "TXT_RADIUS = 50\n",
    "TXT_ITERATION = 1\n",
    "TXT = DIL ERO BHT\n",
    "```\n",
    "\n",
    "describe the radius to be applied for texture computation (meters for FORCE DataCube), the number of iterations (i.e. 3 means the texture is iteratively calculated three times, which increases texture effect), and the kind of texture. Currently available metrics are dilation, erosion, opening, closing, gradient, blackhat and tophat. For an encompassing description of parameterization, please see the [FORCE \n",
    "documentation ](https://force-eo.readthedocs.io/en/latest/components/higher-level/txt/param.html).\n",
    "\n",
    "### Output Data\n",
    "\n",
    "Output data are organized in the FORCE DataCube format.\n",
    "\n",
    "Example filename: *TEXTURE_HL_TXT_CLS.tif*\n",
    "\n",
    "The output of the Texture Metrics submodule is rather standardized, as the user can only choose between different morphological metrics to be applied. TEXTURE is the name base that can be adapted by the user in the parameter file. Here, CLS is the closing operator tag. The data is represented in the same type as the input data, e.g. reflectance with a scale of 10000 if ARD from the FORCE DataCube is used.\n",
    "\n",
    "### Working Example\n",
    "\n",
    "CODE-DE users can download a working example of a Texture Metrics  parameter file [here](https://github.com/CODE-DE-Cloud/community_FORCE/tree/main/examples/parameter_files), or directly use the parameter file as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dforce force-higher-level force-prm-TXT.prm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This generates dilation and erosion metrics from the 25th, 50th and 75th percentile of reflectance of all clear sky observations of Sentinel-2 A/B imagery as generated by the parameter file presented in the Time Series Analysis section.\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "Please refer to the [FORCE Texture Metrics documentation](https://force-eo.readthedocs.io/en/latest/components/higher-level/txt/index.html#txt) with a processing workflow illustration for further detail.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Landscape Metrics\n",
    "\n",
    "The Landscape Metrics submodule quantifies spatial patterns of a given feature. This submodule uses a continuous moving window approach and computes a set of landscape metrics for each pixel and its surrounding area within a specified radius, for example edge density, the number of patches, or mean patch area. It also computes arithmetic and geometric mean, standard deviation and maximum of all pixel values within this radius.\n",
    "\n",
    "### Input Data\n",
    "\n",
    "This submodule typically uses hARD+ products, i.e. datasets immediately ready to analyze, such as land cover maps, because that is often where spatial patterns are of interest. The submodule accepts cubed raster data with a discrete or continuous data structure, including external hARD+ ingested by using [force-cube](https://force-eo.readthedocs.io/en/latest/components/auxilliary/cube.html).\n",
    "\n",
    "### Parameter file\n",
    "\n",
    "Create a Landscape Metrics parameter file with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``dforce force-parameter force-prm-LSM.prm LSM``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: we are skipping this step as the community repository already contains working examples.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Landscape Metrics parameter file uses an INPUT_FEATURE parameter that points at all features that Landscape Metrics should be computed for (file name followed by an enumeration of bands). LSM_RADIUS describe the radius to be applied for landscape metrics computation in data cube projection units (meters for FORCE DataCube). LSM_KERNEL_SHAPE indicates whether a circular or squared kernel should be used as a moving window. LSM_MIN_PATCHSIZE describes the minimum number of pixels of a patch in order to be considered a patch (i.e. 1 means no minimum).\n",
    "\n",
    "LSM_THRESHOLD_TYPE defines the type of the threshold that is used to define the foreground class (greater then, greater than or equal to, less than, less than or equal to, equal to) for each given feature. The list needs to be as long as there are features. LSM_THRESHOLD defines the threshold. All pixels that are greater than, lower than or equal to this threshold are defined as foreground class. Landscape metrics are computed for pixels covererd by the foreground class. No metrics are computed for the pixels covered by the background class. The list needs to be as long as there are features (including bands). For statistical metrics (e.g. geometric mean), these thresholds are used as a mask. LSM_ALL_PIXELS determines if the landscape metrics are also calculated for pixels covered by the background class.\n",
    "\n",
    "For an encompassing description of parameterization, please see the [FORCE documentation](https://force-eo.readthedocs.io/en/latest/components/higher-level/lsm/param.html).\n",
    "\n",
    "### Output Data\n",
    "\n",
    "Output data are organized in the FORCE DataCube format.\n",
    "\n",
    "Example filename: LSMBASE_HL_LSM_MPA.tif\n",
    "\n",
    "The output of the Landscape Metrics submodule is rather standardized, as the user can only choose between different metrics to be applied. LSM is the name base that can be adapted by the user in the parameter file. Here, MPA is the mean patch area tag.\n",
    "\n",
    "The output data format is depending on the selected landscape metrics to be computed. For arithmetic and geometric mean, standard deviation and maximum, the output format corresponds to the input feature format. Unique patch ID is nominal, number of patches is ordinal, weighted mean patch area is in projection units. Please refer to a landscape metrics documentation such as the [FRAGSTATS documentation](https://www.umass.edu/landeco/research/fragstats/documents/Metrics/Metrics%20TOC.htm) for furtherinformation about landscape metrics.\n",
    "\n",
    "### Working Example\n",
    "\n",
    "CODE-DE users can download a working example of a Landscape Metrics parameter file [here](https://github.com/CODE-DE-Cloud/community_FORCE/tree/main/examples/parameter_files), or directly use the parameter file as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dforce force-higher-level force-prm-LSM.prm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This generates the Mean Patch Area of all vegetation patches, defined by pixels with an NDVI above 0.5, based on the 25th, 50th and 75th percentile of the NDVI of all clear sky observations of Sentinel-2 A/B imagery as generated by the parameter file presented in the Time Series Analysis section.\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "Please refer to the [FORCE Landscape Metrics documentation](https://force-eo.readthedocs.io/en/latest/components/higher-level/lsm/index.html#lsm)for further detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Defined Functions\n",
    "    \n",
    "The User Defined Functions submodule provides an interface that allows FORCE users to benefit from FORCE processing capabilities and datacube structures with user-written Python functions. These UDFs only contain the algorithm itself, while data handling is completely organized by FORCE. Users can plug in simple scripts, complicated algorithms, or existing Python implementations of commonly used packages, such as BFAST, or LandTrendr.\n",
    "\n",
    "### Input Data\n",
    "\n",
    "This submodule requires an existing Python file (.py) as well as any kind of (cubed) ARD, hARD, or hARD+ datasets, depending on the specific functionality of the user-defined function.\n",
    "\n",
    "### Parameter file\n",
    "\n",
    "Create a User Defined Functions parameter file with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``dforce force-parameter force-prm-UDF.prm UDF``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: we are skipping this step as the community repository already contains working examples.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PYTHON UDF PARAMETERS is the essential component of the UDF parameter file. Here, the path to the python file is given (FILE_PYTHON), and the type of the function.\n",
    "\n",
    "PIXEL expects a pixel-function that receives the time series of a single pixel as 4D-nd array ``[nDates, nBands, nrows, ncols]``. BLOCK expects a pixel-function that receives the time series of a complete  processing unit as 4D-nd.array ``[nDates, nBands, nrows, ncols]``. No parallelization is done on FORCE's end.\n",
    "\n",
    "### Output Data\n",
    "\n",
    "Output data types are largely defined by the user’s requirements.\n",
    "\n",
    "### Working Example\n",
    "\n",
    "CODE-DE users can download a working example of a User Defined Functions parameter file [here](https://github.com/CODE-DE-Cloud/community_FORCE/tree/main/examples/parameter_files), or directly use the parameter file as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dforce force-higher-level force-prm-UDF.prm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This generates data containing Landsat reflectance values extracted from those observations where the Normalized Difference Vegetation Index (NDVI) was highest during the year 2020. The corresponding python script file can be downloaded here.\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "Please refer to this [FORCE User Defined Functions tutorial](https://force-eo.readthedocs.io/en/latest/howto/udf.html) for further detail."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
